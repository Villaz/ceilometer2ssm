#!/usr/bin/env python
import httplib
import urllib
import json
import cStringIO
import re
import os
import sys
import urlparse
import argparse
import subprocess
import shlex
import logging

from time import localtime, strftime
from pwd import getpwnam  
from dateutil import parser
from dirq.QueueSimple import QueueSimple

state_map = {
    # from https://wiki.egi.eu/wiki/Fedcloud-tf:WorkGroups:Scenario4
    "active": "started",
    "build": "started",
    "deleted": "completed",
    "error": "error",
    "hard_reboot": "started",
    "migrating": "started",
    "paused": "paused",
    "reboot": "started",
    "rebuild": "started",
    "confirming_resize": "started",
    "rescue": "started",
    "resize": "started",
    "revert_resize": "started",
    "password": "started",
    "verify_resize": "started",
    "shutoff": "completed",
    "suspended": "suspended",
    "terminated": "completed",
    "stopped": "completed",
    "saving": "started"
    }


def read_config(filename):
    # read the mapping of project-id to accounting group from a file
    try:
        f = open(filename,"r")
        try:
            result=json.loads(f.read())
            f.close
            return result
        except:
            logging.error("Cannot parse configuration file " + filename)
            exit(1)
    except IOError:
        logging.error('Cannot open configuration file ' + filename)
        exit(1)
        

def auth_keystone(keystoneserver, username, password, tenant, cacert, debug):
    auth = '{"auth":{"passwordCredentials":{"username":"' + username + '","password":"' + password + '"}, "tenantName":"' + tenant + '"}}'
    auth_server = urlparse.urlparse(keystoneserver)[1]
    auth_protocol = urlparse.urlparse(keystoneserver)[0]
    auth_path = urlparse.urlparse(keystoneserver)[2]
    if auth_protocol == "https":
     Newconn = httplib.HTTPSConnection
    else:
     Newconn = httplib.HTTPConnection

    header = {"Content-type": "application/json"}
    req = "POST"
    get_auth_conn = Newconn(auth_server)
    try:
        get_auth_conn.request(req, auth_path, auth, header)
        answer = get_auth_conn.getresponse()
        if answer.status == 200:
         if (debug):
          logging.error("Keystone authentication succeeded")
         return answer.read()
        else:
         logging.error("Failed to get keystone token from " + keystone_server)
         logging.error(answer.reason)
    except:
        logging.error('An error occurred while connecting to keystone server')
        exit(1)

def receive_data(verbose, debug, keystone_response, start, end, meter):
    decoded = json.loads(keystone_response)
    tokenid = decoded["access"]["token"]["id"]
    uri = '/v2/meters/%s' % meter
    for endpoint in decoded["access"]["serviceCatalog"]:
        if (endpoint["name"] == "ceilometer"):
            for ceilometers in endpoint["endpoints"]:
                ceilometer_server = urlparse.urlparse(ceilometers["publicURL"])[1]
                ceilometer_protocol = urlparse.urlparse(ceilometers["publicURL"])[0]
                if ceilometer_protocol == "https":
                 NEWconn = httplib.HTTPSConnection
                else:
                 NEWconn = httplib.HTTPConnection
                query = {"q":[{"field":"timestamp", "op":"ge", "value":start}, {"field": "timestamp", "op":"le", "value":end}] }
                data = json.dumps(query)
                header = {"Content-type": "application/json", "X-Auth-Token": tokenid.encode('ascii', 'ignore')}
                req = 'GET'
                if (debug):
                    logging.error("Query ceilometer server at: " + ceilometer_server)
                    logging.error("Query it with: :" + json.dumps(query , indent=2))
                try:
                    get_cm_conn = NEWconn(ceilometer_server)
                    try:
                        get_cm_conn.request(req, uri, body=data, headers=header)
                        res = get_cm_conn.getresponse()
                        if res.status == 200:
                            return json.loads(res.read())
                    except:
                        logging.error("Failed to query ceilometer server at " + ceilometers)
                        exit(1)
                except:
                    logging.error("failed to create the connection object")

def get_uid(username):
    uid = 0
    try:
        uid = getpwnam(username).pw_uid
    except:
        logging.error("Cannot find uid for " + username)
        uid = getpwnam('nobody').pw_uid
    return uid 

def get_accgroup(filter, mapping, report_groups, project):
    # return the accounting group
    try:
        gid = mapping[project]["group"]
        if (filter):
            try: 
                report_groups.index(gid)
            except:
                gid = 'unset'
    except:
        gid = 'unknown'
    return gid 

def get_tenant(mapping, project):
    # return the accounting group
    try:
        tenant = mapping[project]["name"]
    except:
        tenant = 'NULL'
    return tenant 


def ana_received_cpu_data(verbose, debug, filter, mapping, report_groups, cpu_data, hide_names):
    #
    # filter for start and end records
    #
    ssm_record = {}
    try:
        for record in cpu_data:
            resource_id = record['resource_id']
            timestamp = parser.parse(record['timestamp']).strftime("%s")
            gid = get_accgroup(filter, mapping, report_groups, record['project_id'])
            if debug:
                print "processing resource_id " + resource_id + " in project " + record['project_id'] + " accounting group: " + gid
            if (gid == 'unset' or (filter and (gid == 'NULL'))):
                if debug:
                    print >> sys.stderr, "Debug: skipped input record = " + json.dumps(record , indent=2)   
                pass
            else:
                # memorize relevant data and find start and end record
                try:
                    ssm_record[resource_id]
                except KeyError:
                    if debug:
                        print >> sys.stderr, "Debug: new record " + resource_id
                    ssm_record[resource_id] = {}
                    ssm_record[resource_id]['periodstart'] = timestamp
                    ssm_record[resource_id]['periodend'] = timestamp
                    ssm_record[resource_id]['machinename'] = 'NULL'
                    ssm_record[resource_id]['state'] = 'NULL'
                    ssm_record[resource_id]['imageid'] = 'NULL'
                if (timestamp < ssm_record[resource_id]['periodstart']):
                    ssm_record[resource_id]['periodstart'] = timestamp
                else:
                    if (timestamp >= ssm_record[resource_id]['periodend']):
                        if debug:
                            print >> sys.stderr, "Debug Updating record " + resource_id + " start: " + ssm_record[resource_id]['periodstart'] + " end : " + timestamp
                        ssm_record[resource_id]['periodend'] = timestamp
                        ssm_record[resource_id]['tenant'] = get_tenant(mapping, record['project_id'])
                        ssm_record[resource_id]['vmuuid'] = resource_id
                        uid = record['user_id']
                        memory = record['resource_metadata']['memory_mb']
                        vcpu = record['resource_metadata']['vcpus']
                        try:
                            ssm_record[resource_id]['imageid'] = record['resource_metadata']['image_ref_url']
                        except:
                            pass
                        disk = record['resource_metadata']['disk_gb']
                        try:
                            ssm_record[resource_id]['state'] = state_map[record['resource_metadata']['state']]
                        except:
                            pass
                        try:
                            ssm_record[resource_id]['starttime'] = parser.parse(record['resource_metadata']['created_at']).strftime("%s")
                        except:
                            pass
                        try:
                            # ssm_record[resource_id]['endtime'] = parser.parse(record['resource_metadata']['deleted_at']).strftime("%s")
                            endtime = parser.parse(record['resource_metadata']['deleted_at']).strftime("%s")
                            # machine terminated 
                            ssm_record[resource_id]['state'] = "completed"
                            try: 
                                if (ssm_record[resource_id]['endtime'] > endtime):
                                    ssm_record[resource_id]['endtime'] = endtime
                            except:
                                ssm_record[resource_id]['endtime'] = endtime
                        except:
                            pass
                        if record['counter_unit'] == 'ns':
                            cpucount = record['counter_volume']
                        else:
                            logging.error("unknown counter unit type" + record['counter_unit'])
                        
                        if (hide_names):
                            try:
                                ssm_record[resource_id]['machinename'] = record['resource_metadata']['instance_id']
                            except:
                                pass
                            try:
                                uid = str(get_uid(uid))
                            except:
                                uid = "nobody"
                        else:
                            try:
                                ssm_record[resource_id]['machinename'] = record['resource_metadata']['display_name']
                            except:
                                pass
                        ssm_record[resource_id]['uid'] = uid
                        ssm_record[resource_id]['gid'] = gid 
                        ssm_record[resource_id]['cpucount'] = cpucount
                        ssm_record[resource_id]['vcpu'] = vcpu
                        ssm_record[resource_id]['memory'] = memory
                        ssm_record[resource_id]['disk'] = disk
    except TypeError:
        logging.error("No CPU usage data information has been received")
        exit(1)
    return ssm_record

def ana_received_net_data(verbose, debug, ssm_record, filter, mapping, report_groups, net_data, hide_names):
    #
    # filter for start and end records
    #
    try:
        for record in net_data:
            gid = get_accgroup(filter, mapping, report_groups, record['project_id'])
            if (gid == 'unset' or (filter and (gid == 'NULL'))):
                pass
            else:
                # memorize relevant data and find start and end record
                resource_id = record['resource_metadata']['instance_id']
                timestamp = record['timestamp']
                counter_name = record['counter_name']
                if record['counter_unit'] == 'B':
                    netcount = record['counter_volume']
                else:
                    logging.error("unknown counter unit type" + record['counter_unit'])
                    
                try: 
                    ssm_record[resource_id][counter_name]
                    if (timestamp < ssm_record[resource_id][counter_name]['periodstart']):
                        ssm_record[resource_id][counter_name]['periodstart'] = timestamp
                    if (timestamp > ssm_record[resource_id][counter_name]['periodend']):
                        ssm_record[resource_id][counter_name]['periodend'] = timestamp
                        ssm_record[resource_id][counter_name]['counter_value'] = netcount                            
                except KeyError:
                    ssm_record[resource_id][counter_name] = {}
                    ssm_record[resource_id][counter_name]['periodstart'] = timestamp                    
                    ssm_record[resource_id][counter_name]['periodend'] = timestamp
                    ssm_record[resource_id][counter_name]['counter_value'] = netcount
    except TypeError:
        logging.error("No network usage data information has been received")
        exit(1)
    return ssm_record

def PrintSSMRecords(ssm, sitename, verbose, debug):
    line = "APEL-cloud-message: %s\n" % "v0.2"
    for resource_id in ssm.keys():
        if ssm[resource_id]:
            if (verbose):
                try:
                    logging.info("reported period: from " + ssm[resource_id]['periodstart'] + " to " + ssm[resource_id]['periodend'])
                except KeyError:
                    logging.error("--------------------")
                    logging.error("cannot find periodstart for resource " + resource_id)
                    logging.error(json.dumps(ssm[resource_id], indent=2))
                    logging.error("--------------------")
            line += "VMUUID: %s\n" % ssm[resource_id]['vmuuid']
            line += "SiteName: %s\n" % sitename
            line += "MachineName: %s\n" % ssm[resource_id]['machinename']
            line += "LocalUserId: %s\n" % str(ssm[resource_id]['uid'])
            line += "LocalGroupId: %s\n" % str(ssm[resource_id]['gid'])
            line += "GlobalUserName: NULL\n"
            line += "FQAN: NULL\n"
            if (ssm[resource_id]['state'] == "running"):
                line += "Status: %s\n" % "NULL"
            else:
                line += "Status: %s\n" % ssm[resource_id]['state']
            try:
                line += "StartTime: %d\n" % int(ssm[resource_id]['starttime'])
            except:
                line += "StartTime: %d\n" % 0
                if (debug):
                    print >> sys.stderr, "DEBUG: starttime is not set. Skipping"
            try:
                endtime = int(ssm[resource_id]['endtime'])
            except:
                endtime = 0
            line += "EndTime: %d\n" % int(endtime)

            try:
                starttime = int(ssm[resource_id]['starttime'])
            except:
                starttime = 0
            if (endtime > 0 and starttime > 0):
              walltime = endtime - starttime
            else:
              walltime = int(ssm[resource_id]['periodend']) - starttime

            line += "WallDuration: %d\n" % int(walltime)
            line += "CpuDuration: %d\n" % int(0.5 + float(ssm[resource_id]['cpucount']) / 1000000000.0)
            try:
                line += "CpuCount: %d\n" % int(ssm[resource_id]['vcpu'])
            except:
                line += "CpuCount: %d\n" % 0
                if (debug):
                    print >> sys.stderr, "DEBUG: cannot get cpu count. Skipping"
                    print >> sys.stderr, ssm[resource_id]['vcpu']
            line += "%s\n" % "NetworkType: NULL"
            try:
                line += "NetworkInbound: %d\n" % int(0.5 + float(ssm[resource_id]['network.incoming.bytes']['counter_value']) / 1073741824.0)
            except:
                if (debug):
                    print >> sys.stderr, "DEBUG: Inbound traffic is not set. Skipping"
            try:
                line += "NetworkOutbound: %s\n" % int(0.5 + float(ssm[resource_id]['network.outgoing.bytes']['counter_value']) / 1073741824.0)
            except :
                if (debug):
                    print >> sys.stderr, "DEBUG: Outbound traffic is not set. Skipping"
            try:
                line += "Memory: %d\n" % int(ssm[resource_id]['memory'])
            except :
                if (debug):
                    print >> sys.stderr, "DEBUG: memory is not set. Skipping"
                    print >> sys.stderr, ssm[resource_id]['memory']
            try:
                line += "Disk: %d\n" % int(ssm[resource_id]['disk'])
            except:
                if (debug):
                    print >> sys.stderr, "DEBUG: disk is not set. Skipping"
            # to be added later on
            # line += "GlobalUserName: %s\n" % "NULL"
            # line += "%s\n" % "FQAN: NULL"
            # line += "SuspendDuration: %s\n" % "NULL"
            line += "StorageRecordId: %s\n" % "NULL"
            line += "ImageId: %s\n" % str(ssm[resource_id]['imageid'])
            line += "CloudType: %s\n" % "OpenStack"
            line += "%s\n" % "%%"
    return line

def CreateReport(ssm, verbose, debug):
    report = "Last Update:" + strftime("%a, %d %b %Y %H:%M:%S", localtime()) + "\n"
    report += "| *Accounting group* | *VMs* | *CPUs* | *disk* | *cpu time* | *memory* | *net in* | *net out* | \n"
    by_accgroup = {}
    for resource_id in ssm.keys():
        try: 
            by_accgroup[ssm[resource_id]['gid']]
        except KeyError:
            by_accgroup[ssm[resource_id]['gid']] = {}

        try:
            by_accgroup[ssm[resource_id]['gid']]['nvms'] += 1
        except KeyError:
            by_accgroup[ssm[resource_id]['gid']]['nvms'] = 1 

        try:
            by_accgroup[ssm[resource_id]['gid']]['ncores'] += int(ssm[resource_id]['vcpu'])
        except KeyError:
            by_accgroup[ssm[resource_id]['gid']]['ncores'] = int(ssm[resource_id]['vcpu'])

        try:
            by_accgroup[ssm[resource_id]['gid']]['disk'] += int(ssm[resource_id]['disk']) 
        except KeyError:
            by_accgroup[ssm[resource_id]['gid']]['disk'] = int(ssm[resource_id]['disk'])

        try:
            by_accgroup[ssm[resource_id]['gid']]['cpucount'] += int(ssm[resource_id]['cpucount'] / 1000000000.0)
        except KeyError:
            by_accgroup[ssm[resource_id]['gid']]['cpucount'] = int(ssm[resource_id]['cpucount'] / 1000000000.0)

        try:
            by_accgroup[ssm[resource_id]['gid']]['memory'] += int(ssm[resource_id]['memory'])
        except KeyError:
            by_accgroup[ssm[resource_id]['gid']]['memory'] = int(ssm[resource_id]['memory'])
  
        try:
            by_accgroup[ssm[resource_id]['gid']]['net_in'] += float(ssm[resource_id]['network.incoming.bytes']['counter_value'] / 1073741824.0)
        except KeyError:
            try:
                by_accgroup[ssm[resource_id]['gid']]['net_in'] = float(ssm[resource_id]['network.incoming.bytes']['counter_value'] / 1073741824.0)
            except KeyError:
                 by_accgroup[ssm[resource_id]['gid']]['net_in'] = 0

        try:
            by_accgroup[ssm[resource_id]['gid']]['net_out'] += float(ssm[resource_id]['network.outgoing.bytes']['counter_value'] / 1073741824.0)
        except KeyError:
            try:
                by_accgroup[ssm[resource_id]['gid']]['net_out'] = float(ssm[resource_id]['network.outgoing.bytes']['counter_value'] / 1073741824.0)
            except KeyError:
                by_accgroup[ssm[resource_id]['gid']]['net_out'] = 0


    for accgroup in by_accgroup.keys():
        report += "| " + accgroup + " | " + str(by_accgroup[accgroup]['nvms']) + " | " + str(by_accgroup[accgroup]['ncores']) + " | " + str(by_accgroup[accgroup]['disk']) + " | " + str(by_accgroup[accgroup]['cpucount']) + " | " + str(by_accgroup[accgroup]['memory']) + " | " + str(by_accgroup[accgroup]['net_in']) + " | " + str(by_accgroup[accgroup]['net_out']) + "|\n"

    return report


if __name__ == '__main__':
    aparser = argparse.ArgumentParser(description='Publish ceilometer records to APEL using SSM2')
    aparser.add_argument('-p', '--publish', dest='publish', action='store_true', help='directly publish the data', default=False)
    aparser.add_argument('-v', '--verbose', dest='verbose', action='store_true', help='be verbose', default=False)
    aparser.add_argument('-d', '--debug', dest='debug', action='store_true', help='produce debugging output', default=False)
    aparser.add_argument('-s', '--start', dest='start', action='store', help='start time for the publication', default="2013-09-20T00:00:00")
    aparser.add_argument('-e', '--end', dest='end', action='store', help='end time for the publicatin', default="2013-09-20T23:59:59")
    aparser.add_argument('-c', '--config', dest='configfile', action='store', help='ceilometer2ssm configuration file location', default="/etc/ceilometer2ssm.conf")
    aparser.add_argument('-a', '--apelssmconfig', dest='apelssmconf', action='store', help='location of the apel-ssm configuration file', default='/etc/apel/sender.cfg')
    aparser.add_argument('-l', '--localreport', dest='localreport', action='store_true', help='Create also a local report in Twiki format. Implies --nofilter', default=False)
    aparser.add_argument('-n', '--nofilter', dest='nofilter', action='store_true', help='Do not filter the output for groups', default=False)

    args = aparser.parse_args()
    start = args.start
    end = args.end
    publish = args.publish
    verbose = args.verbose
    debug = args.debug
    configfile = args.configfile
    apelssmconf = args.apelssmconf
    localreport = args.localreport
    nofilter = args.nofilter

    if (debug):
        verbose = True
        print >> sys.stderr, "Debug mode is enabled: will not actually publish but just retrieve the data and report!"

    if (verbose) :
        logging.info("Verbose output will be created")
        logging.info("Reading configuration from " + configfile)
        logging.info("Records are processed between " + start + " and " + end)
        if (publish):
            logging.info("Resulting records will be published to APEL")
        else:
            logging.info("Will not try to publish the result")

    # read mapping from file
    config = read_config(configfile)
    mapping = config["mapping"]
    sitename = config["sitename"]
    report_groups = config["report_groups"]
    hide_names = config["hide_names"]

    try:
        secrets = config["secrets"]
    except:
        if (verbose):
            logging.info("No secrets defined in the configuration file")
    
    try:
        os_auth_url = secrets["os_auth_url"]
    except:
        try:
            os_auth_url = os.environ['OS_AUTH_URL']
        except KeyError:
            logging.error("OS_AUTH_URL is not set")
            exit(1)
    try:
        os_username = secrets["os_username"]
    except:
        try:
            os_username = os.environ['OS_USERNAME']
        except KeyError:
            logging.error("OS_USERNAME is not set")
            exit(1)

    try:
        os_password = secrets["os_password"]
    except:
        try:
            os_password = os.environ['OS_PASSWORD']
        except KeyError:
            logging.error("OS_PASSWORD is not set")
            exit(1)

    try:
        os_tenant_name = secrets["os_tenant_name"]
    except:
        try:
            os_tenant_name = os.environ['OS_TENANT_NAME']
        except KeyError:
            logging.error("OS_TENANT_NAME is not set")
            exit(1)

    try:
        os_cacert = secrets["os_cacert"]
    except:
        try:
            os_cacert = os.environ['OS_CACERT']
        except KeyError:
            logging.error("OS_CACERT is not set")
            exit(1)

    if (debug):
        print >> sys.stderr, "Getting authentication token from keystone"

    keystone_response = auth_keystone(os_auth_url + '/tokens', os_username, os_password, os_tenant_name, os_cacert, debug)

    if (debug):
        print >> sys.stderr, "Keystone response:"
        print >> sys.stderr, json.dumps(keystone_response, indent=2)
        print >> sys.stderr, "reading cpu and net information from ceilometer"

    #
    # retrieve data and analyse
    #

    # cpu
    if (verbose):
        logging.info("reading data from ceilometer")
    cpu_used = receive_data(verbose, debug, keystone_response, start, end, 'cpu')
    net_in = receive_data(verbose, debug, keystone_response, start, end, 'network.incoming.bytes')
    net_out = receive_data(verbose, debug, keystone_response, start, end, 'network.outgoing.bytes')

    if (verbose):
        logging.info("analysing data")
    ssm_filtered = ana_received_cpu_data(verbose, debug, nofilter, mapping, report_groups, cpu_used, hide_names)
    ssm_filtered = ana_received_net_data(verbose, debug, ssm_filtered, nofilter, mapping, report_groups, net_in, hide_names)
    ssm_filtered = ana_received_net_data(verbose, debug, ssm_filtered, nofilter, mapping, report_groups, net_out, hide_names)

    #
    # print the result
    #
    records = PrintSSMRecords(ssm_filtered, sitename, verbose, debug)
    if verbose:
        logging.info(records)

    if (localreport):
        nofilter = True
        if (verbose):
            logging.info("analysing all data")


        ssm_full = ana_received_cpu_data(verbose, debug, nofilter, mapping, report_groups, cpu_used, hide_names)
        ssm_full = ana_received_net_data(verbose, debug, ssm_full, nofilter, mapping, report_groups, net_in, hide_names)
        ssm_full = ana_received_net_data(verbose, debug, ssm_full, nofilter, mapping, report_groups, net_out, hide_names)
        twiki_report = CreateReport(ssm_full, verbose, debug)
        print twiki_report

    if (publish):
        dirq = QueueSimple('/var/spool/apel/outgoing/')
        dirq.add(records)
        command_line = "/usr/bin/ssmsend --config " + apelssmconf
        if (debug):
            print >> sys.stderr, "Would now run \"" + command_line + "\""
        else:
            args = shlex.split(command_line)
            try:
                p = subprocess.Popen(args)
                if (p.wait() != 0):
                    logging.error(p)
                    exit(1)
            except:
                logging.error("Failed to send the message")
                exit(1)
            
